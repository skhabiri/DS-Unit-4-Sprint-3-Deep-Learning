{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/skhabiri/DS-Unit-4-Sprint-3-Deep-Learning/blob/main/module1-rnn-and-lstm/LS_DS17_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LizDUOc1l-I"
   },
   "source": [
    "## *Data Science Unit 4 Sprint 3 Module 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXX1KDHC1l-J"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of The Complete Works of William Shakespeare, by William Shakespeare\\r\\n\\r\\nThis eBook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this eBook or online at\\r\\nwww.gutenberg.org. If you are not located in the United States, you\\r\\nwill have to check the laws of the country'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://github.com/skhabiri/ML-DeepLearning/raw/main/data/100-0.txt\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "data = r.text\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'title': 'THE TRAGEDY OF ANTONY AND CLEOPATRA', 'start': -99},\n",
       " 1: {'title': 'AS YOU LIKE IT', 'start': -99},\n",
       " 2: {'title': 'THE COMEDY OF ERRORS', 'start': -99},\n",
       " 3: {'title': 'THE TRAGEDY OF CORIOLANUS', 'start': -99},\n",
       " 4: {'title': 'CYMBELINE', 'start': -99},\n",
       " 5: {'title': 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK', 'start': -99},\n",
       " 6: {'title': 'THE FIRST PART OF KING HENRY THE FOURTH', 'start': -99},\n",
       " 7: {'title': 'THE SECOND PART OF KING HENRY THE FOURTH', 'start': -99},\n",
       " 8: {'title': 'THE LIFE OF KING HENRY THE FIFTH', 'start': -99},\n",
       " 9: {'title': 'THE FIRST PART OF HENRY THE SIXTH', 'start': -99},\n",
       " 10: {'title': 'THE SECOND PART OF KING HENRY THE SIXTH', 'start': -99},\n",
       " 11: {'title': 'THE THIRD PART OF KING HENRY THE SIXTH', 'start': -99},\n",
       " 12: {'title': 'KING HENRY THE EIGHTH', 'start': -99},\n",
       " 13: {'title': 'KING JOHN', 'start': -99},\n",
       " 14: {'title': 'THE TRAGEDY OF JULIUS CAESAR', 'start': -99},\n",
       " 15: {'title': 'THE TRAGEDY OF KING LEAR', 'start': -99},\n",
       " 16: {'title': 'LOVE’S LABOUR’S LOST', 'start': -99},\n",
       " 17: {'title': 'THE TRAGEDY OF MACBETH', 'start': -99},\n",
       " 18: {'title': 'MEASURE FOR MEASURE', 'start': -99},\n",
       " 19: {'title': 'THE MERCHANT OF VENICE', 'start': -99},\n",
       " 20: {'title': 'THE MERRY WIVES OF WINDSOR', 'start': -99},\n",
       " 21: {'title': 'A MIDSUMMER NIGHT’S DREAM', 'start': -99},\n",
       " 22: {'title': 'MUCH ADO ABOUT NOTHING', 'start': -99},\n",
       " 23: {'title': 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE', 'start': -99},\n",
       " 24: {'title': 'PERICLES, PRINCE OF TYRE', 'start': -99},\n",
       " 25: {'title': 'KING RICHARD THE SECOND', 'start': -99},\n",
       " 26: {'title': 'KING RICHARD THE THIRD', 'start': -99},\n",
       " 27: {'title': 'THE TRAGEDY OF ROMEO AND JULIET', 'start': -99},\n",
       " 28: {'title': 'THE TAMING OF THE SHREW', 'start': -99},\n",
       " 29: {'title': 'THE TEMPEST', 'start': -99},\n",
       " 30: {'title': 'THE LIFE OF TIMON OF ATHENS', 'start': -99},\n",
       " 31: {'title': 'THE TRAGEDY OF TITUS ANDRONICUS', 'start': -99},\n",
       " 32: {'title': 'THE HISTORY OF TROILUS AND CRESSIDA', 'start': -99},\n",
       " 33: {'title': 'TWELFTH NIGHT; OR, WHAT YOU WILL', 'start': -99},\n",
       " 34: {'title': 'THE TWO GENTLEMEN OF VERONA', 'start': -99},\n",
       " 35: {'title': 'THE TWO NOBLE KINSMEN', 'start': -99},\n",
       " 36: {'title': 'THE WINTER’S TALE', 'start': -99},\n",
       " 37: {'title': 'A LOVER’S COMPLAINT', 'start': -99},\n",
       " 38: {'title': 'THE PASSIONATE PILGRIM', 'start': -99},\n",
       " 39: {'title': 'THE PHOENIX AND THE TURTLE', 'start': -99},\n",
       " 40: {'title': 'THE RAPE OF LUCRECE', 'start': -99},\n",
       " 41: {'title': 'VENUS AND ADONIS', 'start': -99},\n",
       " 42: {'title': '', 'start': -99}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc = [l.strip() for l in data.split('\\r\\n')[44:130:2]]\n",
    "{id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRS3g6Vl1l-N"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\\r (Carriage Return) → moves the cursor to the beginning of the line without advancing to the next line\n",
    "\\n (Line Feed) → moves the cursor down to the next line without returning to the beginning of the line — In a *nix environment \\n moves to the beginning of the line.\n",
    "\\r\\n (End Of Line) → a combination of \\r and \\n\n",
    "\"\"\"\n",
    "\n",
    "url = \"https://github.com/skhabiri/ML-DeepLearning/raw/main/data/100-0.txt\"\n",
    "\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "data = r.text\n",
    "\n",
    "data = data.split('\\r\\n')\n",
    "\n",
    "# Title of the writings\n",
    "toc = [l.strip() for l in data[44:130:2]]\n",
    "\n",
    "# Skip the Table of Contents\n",
    "data = data[135:]\n",
    "\n",
    "# Fixing Titles\n",
    "toc[9] = 'THE LIFE OF KING HENRY V'\n",
    "toc[18] = 'MACBETH'\n",
    "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
    "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
    "\n",
    "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
    "\n",
    "# Start \n",
    "for e,i in enumerate(data):\n",
    "    for t,title in enumerate(toc):\n",
    "        if title in i:\n",
    "            locations[t].update({'start':e})\n",
    "            \n",
    "\n",
    "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
    "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
    "df_toc.loc[42, 'end'] = len(data)\n",
    "df_toc['end'] = df_toc['end'].astype('int')\n",
    "\n",
    "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "BSeKOKHF1l-P",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "outputId": "9c477c43-c025-476f-c2b2-01ea07a6b6b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
       "      <td>-99</td>\n",
       "      <td>14379</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS YOU LIKE IT</td>\n",
       "      <td>14380</td>\n",
       "      <td>17171</td>\n",
       "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THE COMEDY OF ERRORS</td>\n",
       "      <td>17172</td>\n",
       "      <td>20372</td>\n",
       "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
       "      <td>20373</td>\n",
       "      <td>30346</td>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CYMBELINE</td>\n",
       "      <td>30347</td>\n",
       "      <td>30364</td>\n",
       "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  start    end  \\\n",
       "0  THE TRAGEDY OF ANTONY AND CLEOPATRA    -99  14379   \n",
       "1                       AS YOU LIKE IT  14380  17171   \n",
       "2                 THE COMEDY OF ERRORS  17172  20372   \n",
       "3            THE TRAGEDY OF CORIOLANUS  20373  30346   \n",
       "4                            CYMBELINE  30347  30364   \n",
       "\n",
       "                                                text  \n",
       "0                                                     \n",
       "1  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...  \n",
       "2  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...  \n",
       "3  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...  \n",
       "4  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shakespeare Data Parsed by Play\n",
    "df_toc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yLDO4Grn3m1z",
    "outputId": "abd6767e-4de9-4596-f65f-c7755141ff5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sg8JTsm14B9o",
    "outputId": "6e721883-3533-4d35-e2cc-86f9b383e0cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136678"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_toc['text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "id": "IrMrYDOn3t6W",
    "outputId": "d91f91a3-d73b-43ec-f709-7c5c44a4e9e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      \n",
       "1     AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
       "2     THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
       "3     THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
       "4     CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
       "5     THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\r\\n\\r...\n",
       "6     THE FIRST PART OF KING HENRY THE FOURTH\\r\\n\\r\\...\n",
       "7     THE SECOND PART OF KING HENRY THE FOURTH\\r\\n\\r...\n",
       "8                                                      \n",
       "9     THE LIFE OF KING HENRY V\\r\\n\\r\\n\\r\\n\\r\\nConten...\n",
       "10    THE SECOND PART OF KING HENRY THE SIXTH\\r\\n\\r\\...\n",
       "11    THE THIRD PART OF KING HENRY THE SIXTH\\r\\n\\r\\n...\n",
       "12                     KING HENRY THE EIGHTH\\r\\n\\r\\n...\n",
       "13      KING JOHN. O cousin, thou art come to set mi...\n",
       "14    THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...\n",
       "15    THE TRAGEDY OF KING LEAR\\r\\n\\r\\n\\r\\n\\r\\nConten...\n",
       "16    LOVE’S LABOUR’S LOST\\r\\n\\r\\nDramatis Personae....\n",
       "17                                                     \n",
       "18    MACBETH.\\r\\nI will not yield,\\r\\nTo kiss the g...\n",
       "19    THE MERCHANT OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nContents...\n",
       "20    THE MERRY WIVES OF WINDSOR\\r\\n\\r\\nDramatis Per...\n",
       "21    A MIDSUMMER NIGHT’S DREAM\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
       "22     MUCH ADO ABOUT NOTHING\\r\\n\\r\\n\\r\\n\\r\\nContent...\n",
       "23                                                     \n",
       "24    OTHELLO, THE MOOR OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nCon...\n",
       "25    KING RICHARD THE SECOND\\r\\nJOHN OF GAUNT, Duke...\n",
       "26    KING RICHARD THE THIRD\\r\\n\\r\\nDramatis Persona...\n",
       "27    THE TRAGEDY OF ROMEO AND JULIET\\r\\n\\r\\n\\r\\n\\r\\...\n",
       "28    THE TAMING OF THE SHREW\\r\\n\\r\\n\\r\\n\\r\\nContent...\n",
       "29    THE TEMPEST\\r\\n\\r\\n\\r\\n\\r\\nContents\\r\\n\\r\\nACT...\n",
       "30    THE LIFE OF TIMON OF ATHENS\\r\\n\\r\\nDRAMATIS PE...\n",
       "31    THE TRAGEDY OF TITUS ANDRONICUS\\r\\n\\r\\nDramati...\n",
       "32    THE HISTORY OF TROILUS AND CRESSIDA\\r\\n\\r\\n\\r\\...\n",
       "33                                                     \n",
       "34    TWELFTH NIGHT: OR, WHAT YOU WILL\\r\\n\\r\\n\\r\\n\\r...\n",
       "35    THE TWO NOBLE KINSMEN:\\r\\n\\r\\nPresented at the...\n",
       "36    THE WINTER’S TALE\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nContents\\...\n",
       "37    A LOVER’S COMPLAINT\\r\\n\\r\\n\\r\\n\\r\\nFrom off a ...\n",
       "38    THE PASSIONATE PILGRIM\\r\\n\\r\\nI.\\r\\n\\r\\nDid no...\n",
       "39    THE PHOENIX AND THE TURTLE\\r\\n\\r\\n\\r\\n\\r\\nLet ...\n",
       "40    THE RAPE OF LUCRECE\\r\\n\\r\\n                   ...\n",
       "41     VENUS AND ADONIS\\r\\n\\r\\nEven as the sun with ...\n",
       "42                                                     \n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toc['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "O_y6A0LGigSK",
    "outputId": "958c8e1e-5254-4b57-bcc4-6916d795b19f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'S',\n",
       " ' ',\n",
       " 'Y',\n",
       " 'O',\n",
       " 'U',\n",
       " ' ',\n",
       " 'L',\n",
       " 'I',\n",
       " 'K',\n",
       " 'E',\n",
       " ' ',\n",
       " 'I',\n",
       " 'T',\n",
       " '\\r',\n",
       " '\\n',\n",
       " '\\r',\n",
       " '\\n',\n",
       " '\\r',\n",
       " '\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = []\n",
    "for txt in df_toc['text']:\n",
    "  for x in txt:\n",
    "    test.append(x)\n",
    "test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oxxcSOnM5McI"
   },
   "outputs": [],
   "source": [
    "# data = df_toc['text'][1:].values\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r\\n\\r\\n  DUKE, living in exile\\r\\n  FREDERICK, his brother, and usurper of his dominions\\r\\n  AMIENS, lord attending on the banished Duke\\r\\n  JAQUES,   \"      \"       \"  \"     \"      \"\\r\\n  LE BEAU, a courtier attending upon Frederick\\r\\n  CHARLES, wrestler to Frederick\\r\\n  OLIVER, son of Sir Rowland de Boys\\r\\n  JAQUES,   \"   \"  \"    \"     \"  \"\\r\\n  ORLANDO,  \"   \"  \"    \"     \"  \"\\r\\n  ADAM,   servant to Oliver\\r\\n  DENNIS,     \"     \"   \"\\r\\n  TOUCHSTONE, the court jester\\r\\n  SI'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toc['text'][1][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "colab_type": "code",
    "id": "Hw3Lsjf1ifWE",
    "outputId": "67f09857-24d2-42cd-8add-3047bb2f230d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AS YOU LIKE IT      DRAMATIS PERSONAE.      DUKE, living in exile    FREDERICK, his brother, and usurper of his dominions    AMIENS, lord attending on the banished Duke    JAQUES,                                 LE BEAU, a courtier attending upon Frederick    CHARLES, wrestler to Frederick    OLIVER, son of Sir Rowland de Boys    JAQUES,                       ORLANDO,                      ADAM,   servant to Oliver    DENNIS,                 TOUCHSTONE, the court jester    SIR OLIVER MARTEXT, a v'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing \\r\\n and \" from the pd.series and store as a list of strings\n",
    "data = []\n",
    "# txt is each of 43 chapters\n",
    "for txt in df_toc['text']:\n",
    "  # x is each character in a chapter\n",
    "  # white spaces are not removed\n",
    "  t = [x.replace('\\r', ' ').replace('\\n', ' ').replace('\"', '') for x in txt]\n",
    "  data.append(\"\".join(t))\n",
    "print(len(data))\n",
    "# data is a list of 43 items. Each chapter's \\r and \\n is removed, but still has multiple consecutive white spaces\n",
    "data[1][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_WPuqKIjk_O"
   },
   "outputs": [],
   "source": [
    "# For each chapter converts multiple spaces into one space\n",
    "data = [' '.join(data[i].split()) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "G4lrAx8Bk0e7",
    "outputId": "c1dfd3f1-fcce-493b-8208-949cd550f939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AS YOU LIKE IT DRAMATIS PERSONAE. DUKE, living in exile FREDERICK, his brother, and usurper of his dominions AMIENS, lord attending on the banished Duke JAQUES, LE BEAU, a courtier attending upon Frederick CHARLES, wrestler to Frederick OLIVER, son of Sir Rowland de Boys JAQUES, ORLANDO, ADAM, servant to Oliver DENNIS, TOUCHSTONE, the court jester SIR OLIVER MARTEXT, a vicar CORIN, shepherd SILVIUS, WILLIAM, a country fellow, in love with Audrey A person representing HYMEN ROSALIND, daughter to '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IObMjsGZ4_Jz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "In9Zlzpyk_-V",
    "outputId": "a94a9034-f283-42f1-9e4d-99397211c2f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "# connect all the 43 chapters with a space character into a long flattened text\n",
    "# then make the text lower case as well\n",
    "text = ' '.join(data).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N7ZsUv5FoBqJ"
   },
   "outputs": [],
   "source": [
    "# remove all non-related characters\n",
    "text = re.sub(\"[^a-z A-Z.:;?'!,`-]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "KKnQ_rceB3jy",
    "outputId": "b800b564-946b-4b09-f937-12b85546ed9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' as you like it dramatis personae. duke, living in exile frederick, his brother, and usurper of his dominions amiens, lord attending on the banished duke jaques, le beau, a courtier attending upon frederick charles, wrestler to frederick oliver, son of sir rowland de boys jaques, orlando, adam, servant to oliver dennis, touchstone, the court jester sir oliver martext, a vicar corin, shepherd silvius, william, a country fellow, in love with audrey a person representing hymen rosalind, daughter to'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PgO84FQwBpmm",
    "outputId": "8e781715-c853-4cdc-a60b-15c6b0706fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"? n u x k o b w v -   , ! z ` h ; l t : f ' i q a j y e c d g p m . r s\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of all used characters to be used as bag of items, but remove the duplicate characters\n",
    "chars = list(set(text))\n",
    "\n",
    "char_int = {c:i for i, c in enumerate(chars)}\n",
    "int_char = {i:c for i, c in enumerate(chars)}\n",
    "\n",
    "dict_size = len(chars)\n",
    "print(dict_size)\n",
    "\" \".join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "ZybRHGl1mrz6",
    "outputId": "44dd9d7c-7e8f-4caa-a76b-c75b367ddd00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'?': 0,\n",
       " 'n': 1,\n",
       " 'u': 2,\n",
       " 'x': 3,\n",
       " 'k': 4,\n",
       " 'o': 5,\n",
       " 'b': 6,\n",
       " 'w': 7,\n",
       " 'v': 8,\n",
       " '-': 9,\n",
       " ' ': 10,\n",
       " ',': 11,\n",
       " '!': 12,\n",
       " 'z': 13,\n",
       " '`': 14,\n",
       " 'h': 15,\n",
       " ';': 16,\n",
       " 'l': 17,\n",
       " 't': 18,\n",
       " ':': 19,\n",
       " 'f': 20,\n",
       " \"'\": 21,\n",
       " 'i': 22,\n",
       " 'q': 23,\n",
       " 'a': 24,\n",
       " 'j': 25,\n",
       " 'y': 26,\n",
       " 'e': 27,\n",
       " 'c': 28,\n",
       " 'd': 29,\n",
       " 'g': 30,\n",
       " 'p': 31,\n",
       " 'm': 32,\n",
       " '.': 33,\n",
       " 'r': 34,\n",
       " 's': 35}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the text to integer numbers and create sequences of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating character sequences as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zMkbsfVF5wco",
    "outputId": "84ba5c2a-8316-4b93-a8d3-899daa450c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  696793 696794.7\n"
     ]
    }
   ],
   "source": [
    "# sequence length\n",
    "timestep = 40\n",
    "# stepping\n",
    "step = 20\n",
    "\n",
    "# iterate through each character of the text\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One character for each element of sequence\n",
    "\n",
    "for i in range(0, len(encoded) - timestep, step):\n",
    "    sequences.append(encoded[i : i + timestep])\n",
    "    # next_char refers to the character encoding right after the last character of the sequence in encoded list\n",
    "    next_char.append(encoded[i + timestep])\n",
    "    \n",
    "print('sequences: ', len(sequences), len(encoded)/step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SV743DoZ7ndT"
   },
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    \"\"\"\n",
    "    It normalizes the array of preds to proba (with their sum equal to 1)\n",
    "    Then it picks the index of a character based on a random draw considering the proba array weight\n",
    "    \"\"\"\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    \n",
    "    # Null operation\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    \n",
    "    # Normalize to the sum of one for the array of probabilities\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    # Returns the indices of the maximum values along an axis.\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_seq(sentence, timestep, features, embedding=False):\n",
    "    \"\"\"\n",
    "    create a sequence that has an input dimension compatible with NN input layer.\n",
    "    The supported input layers are:\n",
    "    LSTM: output x.shape=[1, timestep, features]\n",
    "    Embedding: output x.shape = [1, timestep]\n",
    "    inputs:\n",
    "    sentence: string sentence of any length to feed into model.predict()\n",
    "    timestep: pads the sentence to a sequence of exactly timestep\n",
    "    features: size of dictionary of words, aka input features\n",
    "    embedding: whether the input layer is embedding or LSTM\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    # make see a fixed length padded with space if smaller\n",
    "    sequence = sentence.rjust(timestep)[:timestep]  \n",
    "    \n",
    "    if embedding:\n",
    "        # encode the characters into integers\n",
    "        x = [char_int[c] for c in sequence]\n",
    "        x = np.array(x)\n",
    "        # model treats the input as 1 input sequence of dynamic length\n",
    "        # x.shape=(1, timestep)\n",
    "        x = np.expand_dims(x,0)\n",
    "\n",
    "    else:\n",
    "        x = np.zeros((1, timestep, features))\n",
    "        for t, char in enumerate(sequence):\n",
    "            x[0, t, char_int[char]] = 1\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and convert text back into characters\n",
    "def generate_text(model, seed, nextsize, timestep=timestep, features=dict_size, embedding=False):\n",
    "    \"\"\"\n",
    "    model: trained model\n",
    "    seed: some phrase for model to generate the next characters\n",
    "    timestep: timestep size of one input sequence to be\n",
    "    nextsize: number of the next characters to generate\n",
    "    embedding: if the input layer is embedding or LSTM\n",
    "    \"\"\"\n",
    "    \n",
    "    # pad left of the sequence with blank space or slice its right side\n",
    "    sequence = seed.lower().rjust(timestep)[:timestep] \n",
    "    \n",
    "    generated = ''\n",
    "    generated += sequence\n",
    "    model.reset_states()\n",
    "\n",
    "    for _ in range(nextsize):\n",
    "        x = shape_seq(sequence, timestep, features, embedding)\n",
    "        \n",
    "        # pred is a numpy array  \n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        \n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        # update the sequence by moving one character forward\n",
    "        sequence = sequence[1:] + next_char\n",
    "        \n",
    "        generated += next_char\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MclR_6Xk7orY"
   },
   "outputs": [],
   "source": [
    "def print_text(epoch_f, logs_f):\n",
    "    \"\"\" Function invoked at end of each epoch. Prints generated text.\n",
    "    LambdaCallback passes epoch integer number and logs dictionary of metrics to this function.\n",
    "    \"\"\"\n",
    "    epoch_f\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch_f)\n",
    "    \n",
    "    # Random prompt to grab a 40 character sample seed\n",
    "    start_index = random.randint(0, len(text) - timestep - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + timestep]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        # 400 is the length of generated text\n",
    "        \n",
    "        x_pred = shape_seq(sentence, timestep, dict_size, embedding=(model!=model_lstm))\n",
    "            \n",
    "        # Predict the next step (character)\n",
    "        # preds is an array of length dict_size \n",
    "        # with all the elements zero except only one of them 1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        # update the seed by moving one character forward\n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 36)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep, dict_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer - LSTM:\n",
    "With LSTM as the input layer we need to specify:\n",
    "* input_shape=[timesteps, fetures] or\n",
    "* input_shape = [None, features] or\n",
    "* input_dim = features\n",
    "> In prediction of all three cases, the sequence could have bigger or smaller step size and it would still work with some warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X, y for LSTM layer,  (batch_size, timestep=40, features=dict_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kei4lHnu6hG4"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sequences), timestep, dict_size), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), dict_size), dtype=np.bool)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "    # y[sequence, next character after sequence in embeded]   \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tREFT9TL7LXH"
   },
   "outputs": [],
   "source": [
    "model_lstm = Sequential()\n",
    "\n",
    "# input method 1\n",
    "model_lstm.add(LSTM(128, input_shape=(timestep, dict_size)))\n",
    "\n",
    "# # input method 2\n",
    "# model_lstm.add(LSTM(128, input_shape=(None, dict_size)))\n",
    "\n",
    "# # input method 3\n",
    "# model_lstm.add(LSTM(128, input_dim=dict_size))\n",
    "\n",
    "\n",
    "\n",
    "# output is the next character after the sequence\n",
    "model_lstm.add(Dense(dict_size, activation='softmax'))\n",
    "\n",
    "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "7xCk58-B7jJU",
    "outputId": "1c86b8f1-56d2-422e-cef2-247dc34169a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 36)                4644      \n",
      "=================================================================\n",
      "Total params: 89,124\n",
      "Trainable params: 89,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2uAnwRVT7vnN",
    "outputId": "a2976c06-9fb6-43c4-f20d-0cd68dbf89aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "86/86 [==============================] - 195s 2s/step - loss: 3.1834\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \" had stomach for them all. desdemona. al\"\n",
      " had stomach for them all. desdemona. alehlfustohve ltt eiunsn,i knihie nur,  a pbmeicwod r ;nw e enooesptdstn ifue o in r,rnloe au ehkheoa,  v ogewstmon,ti e ,h nhees  s wiihasthleylehlv gd. faitut o nofoae ods  rtgn.irehoowuaci oeio kesmskolpatrsan aewoygsta: dkein t t l  htbd do w yuie  een foi; a ui rbit  saftirdeoym;e tlw t  fntainas  eott   aoah e bi i.tn uyreho wtigitothlrfoygelohehlgt lcsllb taensn   e?jhei taenaitvb y fmi ami o\n",
      "Epoch 2/10\n",
      "86/86 [==============================] - 192s 2s/step - loss: 2.8162\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"emn'd desires access to you. angelo. hat\"\n",
      "emn'd desires access to you. angelo. hatheo ssbtourtcougto: henp n, hre oirsgsp toaok gest yressnm fed,y tsmsa eo ire mreind geen s nan oee hae,, tettifu iyo tauur oh tousi hd aur, niel aiagiselyedihend hisststmmed hy ,l letil toec uguhx,th,sslg hote ehetnnhd weifod lfkrpny,ilefmat hflanomaw saod  ihn phus  medde, laaeo  indht refthodanf thoee br wtsloe hio g aditi  uuehld e bne. bou ae  scfcan  oanw a kob ure' .r tuetse o xanve io-aeao\n",
      "Epoch 3/10\n",
      "86/86 [==============================] - 199s 2s/step - loss: 2.5171\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"im to mercy. duke. i never heard the abs\"\n",
      "im to mercy. duke. i never heard the absest hasolsi wi sels yolis loo  ooi. whau doc, pacetan wpreles, thg sie rulp tatn ror dh ans qoua t ke pnu hel.r thrv youdeke.rreel.  too a veceglrlsh whal. yher, uth ooud ganlspeeto. sorn. ove io oon ch thom wd:rnes fonde,sether iax lt or abupy meinov. ateut in, rinng faadr. fhi wa lhl wind theriy .srim be ta;te d fmeree hemld  owkmen; 'rse. blpedle sile trn sita aold hecat man ehef ko methik, sor\n",
      "Epoch 4/10\n",
      "86/86 [==============================] - 205s 2s/step - loss: 2.3458\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"i'll give you a pottle of burnt sack to \"\n",
      "i'll give you a pottle of burnt sack to conake hne id ou payedoruwhttat th ihveo, by pileroun e iflr eillgnghof, mhefrrdis, and,,t, yee draki hot wec tain siturservan. myow san the kes orst te dordef cewis asr; ipe talld fesst musl aor ch thtueferin  aotbet myovito. stertremee, note toow tel o kyom cainditg, lrco yow lg bomdath s? eo wpndo the s ood. ank allithiy syae te, keun. crice mathe  bonath thou metend te t; minte en sinser tous \n",
      "Epoch 5/10\n",
      "86/86 [==============================] - 212s 2s/step - loss: 2.2590\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"ave, madam; he is a kind of chameleon. t\"\n",
      "ave, madam; he is a kind of chameleon. thorilr. xhesto; the romend tho merpe, hed ou ow thee you. e act. wiss sporjysernt her chpoild laje the fares lallo hothui his geascenron. lywajenas, af wiinliondeli graesbis fith tiy e p;oth in oferbe woldt and, hate ous ardoow old thian, lore. phoe, lo ueat the leall cenains wot parsond, mes ipes of will wcatt haisg roudy cucpen-oje to heetrly wrol. for it as payouc fooh hoing haad a thousbliges \n",
      "Epoch 6/10\n",
      "86/86 [==============================] - 222s 3s/step - loss: 2.2006\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"ts go. one thing more rests, that thysel\"\n",
      "ts go. one thing more rests, that thysely, shile dod the wead i mis. tet pant t aid bfatha- or tue adw,s, heus pouret; tha lemighyour of yur mountashio. servel. comend nas, y buths bewloht ho lalls mofgoole: wayd olo nnt-blaris th haure, il tarresy us. far gire, s apare. i en gome. hit imshithand and minn,isld its nikke hes tif donbs, brle-tore my hom ner mekery buthsente het touwse sonetut iome, baimen want bet wime he cuilay. ount wil\n",
      "Epoch 7/10\n",
      "86/86 [==============================] - 189s 2s/step - loss: 2.1549\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"e bark thy body is, sailing in this salt\"\n",
      "e bark thy body is, sailing in this salt ire ow oun s moth wanthe tay our mome hroo. dedalronis. ared. thumvent my kime, i will d muciur, chat to d wors wfot wi hif nqopeliee too hous soulit. peats mourt mouhest, his tiow our oun mouthe ter hengird is in msase ind a esmad wall das nat tle ded heur i adlund not weke betind my erasee m.y hage wale ica. tialle nour yow an inghe, ? hent, githand ay cloves, vials the dor tey theur, entisen?a\n",
      "Epoch 8/10\n",
      "86/86 [==============================] - 199s 2s/step - loss: 2.1145\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"od cousin, further than you should, lest\"\n",
      "od cousin, further than you should, lestee the wilc, whot what bede thomt wi he vorereg. you  of camenttis horstisebloyd, he nere sefer it coo mithlor. i gowitht yous, what all soulof thstllve. pare munt is and athild,? ho, be inturp. iters. andy. angithluth bet wo when cosesi for? thour. asceroud not; an sther thimetreffore aldir. ar: lawre. tiby, i va io the; realt, bamens foutrat'tor of i hing dopect.e, thallquay. hyboe lang, fort we\n",
      "Epoch 9/10\n",
      "86/86 [==============================] - 188s 2s/step - loss: 2.0841\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"ayd the fool, it was my negligence, not \"\n",
      "ayd the fool, it was my negligence, not in thinf if thaind thoy te achen palmee of i went whe lavin his lercamuns 'ach tresatrar. campor dit. nelain. hersprepordly, mad hit wad he sperith with is then cord to mothis. will aise andes, any baed i hingh be chaxes as ust atgrubles draviod's stise ho rilogest bucenfel you hef morge. herit. thy lequot. ruuch, not and wiroment thin thou sive shats, a gotn ungrevithy, shemwaly. pare filluca. th\n",
      "Epoch 10/10\n",
      "86/86 [==============================] - 196s 2s/step - loss: 2.0520\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"l be more jealous of thee than a barbary\"\n",
      "l be more jealous of thee than a barbary wis, ih wheth thoughmouss yo med? weat and forer, maks, thoughqurond! pris to sies ecerimarou houss i mo low; whes notarcsoppotrruged that is isoremuro? a vismasrurd, a, le thi haffions veors sadlle, with jurancey, wexe, in dariged, and you hinse sthare aveors prayou heravisina. goond youl wiah; a the woy jead ntawed ane bobe my homeerours othe gor'd the samcers, whitheme nive dumyentede turn on \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feda3810630>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on_epoch_end event epoch and logs are returned to the custom function inside Lambdacallback\n",
    "model = model_lstm\n",
    "lcb = LambdaCallback(on_epoch_end=print_text)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "model_lstm.fit(x, y,\n",
    "          batch_size=8192,\n",
    "          epochs=10,\n",
    "          callbacks=[lcb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ShakespeareBot_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ShakespeareBot_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('ShakespeareBot_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model_loaded = keras.models.load_model('ShakespeareBot_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = \"In the darkest night of the year, \"\n",
    "len(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that the trained model works with sequences which have smaller or bigger time step compared to the trained timestep as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 40, 36) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40, 36), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 45, 36).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 40, 36) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40, 36), dtype=tf.float32, name='lstm_input'), name='lstm_input', description=\"created by layer 'lstm_input'\"), but it was called on an input with incompatible shape (None, 45, 36).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"           in the darkest night of the year, ralisinsh. i to frezire! teeleattarior, on athis moswis wemiole pore in usalian. thou you culeming hoy foo shead sish. endmy sabe to kert weer of the four, dercackd. thars: is uneming ixtongo merles, woons not the gotito frold of ty a aint. supround bat yio moust of illo saon to the enediel cunster cffilce eraver it dike. gice to pfou i speak farke of aloun'd owwy to thear hxteen havrs beigicsunca as. inor metal tors thrighy hicesdary. hice; enser woll fo thak aqoie, higla. so gentes you arke se\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_loaded, seed, nextsize=500, timestep=timestep+5, features=dict_size, embedding=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input layer - Embedding:\n",
    "\n",
    "With Embedding as input layer, we can specify different ways:\n",
    "1. input_dim=features or\n",
    "2. input_dim=features, input_length=stepsize or\n",
    "3. input_dim=features, input_shape=(stepsize,)\n",
    "> In prediction of all three cases, the sequence could have bigger or smaller step size and it would still work with some warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (696793, 40))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for embedding layer we need to use sequence to fix the size of input\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# Pad sequences so all are equal\n",
    "seq = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=timestep)\n",
    "type(seq), seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model: with embedding\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import Bidirectional, Embedding\n",
    "\n",
    "model_embed = Sequential()\n",
    "\n",
    "# define input layer\n",
    "# # method1, timestep will be derived dynamically\n",
    "# model_embed.add(Embedding(output_dim=64, input_dim=dict_size))\n",
    "\n",
    "# # method2, timestep of the sequence is fixed:\n",
    "# # The query input still can be in different timesteps and we would only get warning\n",
    "model_embed.add(Embedding(input_dim=dict_size, output_dim = 64, input_length=timestep))\n",
    "\n",
    "# # method3, use input_shape to define timestep\n",
    "# model_embed.add(Embedding(output_dim=64, input_dim=dict_size, input_shape=(timestep,)))\n",
    "\n",
    "\n",
    "\n",
    "model_embed.add(Bidirectional(LSTM(64, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model_embed.add(Dense(dict_size, activation='softmax'))\n",
    "\n",
    "model_embed.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "7xCk58-B7jJU",
    "outputId": "1c86b8f1-56d2-422e-cef2-247dc34169a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 64)            2304      \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                4644      \n",
      "=================================================================\n",
      "Total params: 72,996\n",
      "Trainable params: 72,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_embed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \" ambitious constance would not cease til\"\n",
      " ambitious constance would not cease tilhhnnii ra ht  t.iesecl oomden yrw.iaue, gmlmfweia,cae, sifeu ea  o cbh hr,ce,uiep adtotnmlao;ensnu oe sled  eikiw varo i.ea,tweauwo faesm  lwqntutuc;   howu he lco  hh'hstrf me  wnnaieatn  teosda mreido ue  r n   aoecaemeiehokho.io ao n m isos evmightyrihiiaooq fsaiossaaontitywhhuo .ps asednh issa lcnresntrwoe.  ra fateeboapysre noohvm oh.eltuttfbh b rner'ettwn osbwcpl iowaot ali o.shbidnmee vas s\n",
      "Epoch 2/2\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \" to another man, and do not shear the fl\"\n",
      " to another man, and do not shear the fl mhe dit hfhe m tior od upatetaliuoad rdr ye yee y cosie mlgtoth moneeciin fiuolacis otwept v moieeiaff y maf stlhewwa toai n rnsh. ole. pitegon t usqorerai chine on rolakoe ov muui.n ocecestolo woejye is f thaws,itiae anl reraut t nsd mitrhds teat agen te tlus t, yohuacr uk moc cily cheh yer w, ihosr pol tod trs odik  vrictidoutorrd oeid itaals. y teoc atdoiigegtar fhuye mt thaat. nden baupaoi.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fecbb858940>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_embed\n",
    "lcb = LambdaCallback(on_epoch_end=print_text)\n",
    "\n",
    "# fit the model\n",
    "model_embed.fit(seq, y, batch_size=8192, epochs=2, verbose=10, callbacks=[lcb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ShakespeareBot_embed3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ShakespeareBot_embed3/assets\n"
     ]
    }
   ],
   "source": [
    "model_embed.save('ShakespeareBot_embed3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model_loaded = keras.models.load_model('ShakespeareBot_embed3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 45).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 40) for input KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 45).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'           in the darkest night of the year, s wos ane mocabiknat acet aguld me tonhi y as n naneuc lgashek won d uoagd todlt ibl dgik fsr theb l'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_loaded, seed, nextsize=100, timestep=timestep+5, features=dict_size, embedding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LS_DS17_431_RNN_and_LSTM_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML_ANN (python3.7)",
   "language": "python",
   "name": "ml_ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "0.23.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
